{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.16","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import required lib","metadata":{}},{"cell_type":"code","source":"pip install scikit-learn","metadata":{"execution":{"iopub.status.busy":"2023-04-19T05:34:45.358553Z","iopub.execute_input":"2023-04-19T05:34:45.359183Z","iopub.status.idle":"2023-04-19T05:34:53.345552Z","shell.execute_reply.started":"2023-04-19T05:34:45.359148Z","shell.execute_reply":"2023-04-19T05:34:53.344640Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting scikit-learn\n  Downloading scikit_learn-1.2.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting joblib>=1.1.1\n  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 KB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting threadpoolctl>=2.0.0\n  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/site-packages (from scikit-learn) (1.10.1)\nRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/site-packages (from scikit-learn) (1.23.5)\nInstalling collected packages: threadpoolctl, joblib, scikit-learn\nSuccessfully installed joblib-1.2.0 scikit-learn-1.2.2 threadpoolctl-3.1.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.1 is available.\nYou should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install SimpleITK","metadata":{"execution":{"iopub.status.busy":"2023-04-19T05:34:53.347337Z","iopub.execute_input":"2023-04-19T05:34:53.347606Z","iopub.status.idle":"2023-04-19T05:35:02.738912Z","shell.execute_reply.started":"2023-04-19T05:34:53.347581Z","shell.execute_reply":"2023-04-19T05:35:02.737912Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting SimpleITK\n  Downloading SimpleITK-2.2.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: SimpleITK\nSuccessfully installed SimpleITK-2.2.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.1 is available.\nYou should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install nibabel","metadata":{"execution":{"iopub.status.busy":"2023-04-19T05:35:02.744411Z","iopub.execute_input":"2023-04-19T05:35:02.744690Z","iopub.status.idle":"2023-04-19T05:35:07.972486Z","shell.execute_reply.started":"2023-04-19T05:35:02.744660Z","shell.execute_reply":"2023-04-19T05:35:07.971517Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting nibabel\n  Downloading nibabel-5.1.0-py3-none-any.whl (3.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: importlib-resources>=1.3 in /usr/local/lib/python3.8/site-packages (from nibabel) (5.12.0)\nRequirement already satisfied: packaging>=17 in /usr/local/lib/python3.8/site-packages (from nibabel) (23.0)\nRequirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.8/site-packages (from nibabel) (1.23.5)\nRequirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/site-packages (from importlib-resources>=1.3->nibabel) (3.15.0)\nInstalling collected packages: nibabel\nSuccessfully installed nibabel-5.1.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.1 is available.\nYou should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom torchvision.transforms import RandomHorizontalFlip, RandomRotation, ToTensor, Normalize\nimport nibabel as nib\nfrom scipy.ndimage import zoom\nimport torch.nn as nn\nfrom torchvision.models.video import r3d_18\nimport pandas as pd\nimport SimpleITK as sitk\nimport pickle","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-19T05:35:07.974056Z","iopub.execute_input":"2023-04-19T05:35:07.974423Z","iopub.status.idle":"2023-04-19T05:35:32.547904Z","shell.execute_reply.started":"2023-04-19T05:35:07.974389Z","shell.execute_reply":"2023-04-19T05:35:32.546842Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Load the excel file with paths","metadata":{}},{"cell_type":"code","source":"final_df = pd.read_csv('/kaggle/input/output-excel/final_output.csv')\nfinal_df.info(verbose=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-19T05:35:32.549292Z","iopub.execute_input":"2023-04-19T05:35:32.549714Z","iopub.status.idle":"2023-04-19T05:35:32.585845Z","shell.execute_reply.started":"2023-04-19T05:35:32.549687Z","shell.execute_reply":"2023-04-19T05:35:32.584840Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 2113 entries, 0 to 2112\nData columns (total 7 columns):\n #   Column         Non-Null Count  Dtype \n---  ------         --------------  ----- \n 0   Subject        2113 non-null   object\n 1   Age            2113 non-null   int64 \n 2   Modality       2113 non-null   object\n 3   Group          2113 non-null   object\n 4   Image Data ID  2113 non-null   int64 \n 5   path           2113 non-null   object\n 6   filename       2113 non-null   object\ndtypes: int64(2), object(5)\nmemory usage: 115.7+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"final_df","metadata":{"execution":{"iopub.status.busy":"2023-04-19T05:35:32.587093Z","iopub.execute_input":"2023-04-19T05:35:32.587390Z","iopub.status.idle":"2023-04-19T05:35:32.610661Z","shell.execute_reply.started":"2023-04-19T05:35:32.587366Z","shell.execute_reply":"2023-04-19T05:35:32.609747Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"         Subject  Age Modality Group  Image Data ID   \n0     128_S_0272   71      MRI    CN          68938  \\\n1     128_S_0272   73      MRI    CN         105494   \n2     128_S_0272   72      MRI    CN          69226   \n3     128_S_0272   71      PET    CN          57334   \n4     128_S_0272   74      PET    CN         149234   \n...          ...  ...      ...   ...            ...   \n2108  029_S_1073   67      PET   MCI        1596802   \n2109  029_S_1073   67      PET   MCI        1596748   \n2110  029_S_1073   66      PET   MCI        1596851   \n2111  029_S_1073   68      PET   MCI        1596813   \n2112  029_S_1073   68      MRI   MCI         132818   \n\n                                                   path   \n0     /kaggle/input/adnidata/ADNI/128_S_0272/MPR-R__...  \\\n1     /kaggle/input/adnidata/ADNI/128_S_0272/MPR-R__...   \n2     /kaggle/input/adnidata/ADNI/128_S_0272/MPR-R__...   \n3     /kaggle/input/adnidata/ADNI/128_S_0272/Coreg,_...   \n4     /kaggle/input/adnidata/ADNI/128_S_0272/Coreg,_...   \n...                                                 ...   \n2108  /kaggle/input/adnidata/ADNI/029_S_1073/Coreg,_...   \n2109  /kaggle/input/adnidata/ADNI/029_S_1073/Coreg,_...   \n2110  /kaggle/input/adnidata/ADNI/029_S_1073/Coreg,_...   \n2111  /kaggle/input/adnidata/ADNI/029_S_1073/Coreg,_...   \n2112  /kaggle/input/adnidata/ADNI/029_S_1073/MPR-R__...   \n\n                                               filename  \n0     ADNI_128_S_0272_MR_MPR-R__GradWarp__B1_Correct...  \n1     ADNI_128_S_0272_MR_MPR-R__GradWarp__B1_Correct...  \n2     ADNI_128_S_0272_MR_MPR-R__GradWarp__B1_Correct...  \n3     ADNI_128_S_0272_PT_Coreg,_Avg,_Standardized_Im...  \n4     ADNI_128_S_0272_PT_Coreg,_Avg,_Standardized_Im...  \n...                                                 ...  \n2108  ADNI_029_S_1073_PT_Coreg,_Avg,_Std_Img_and_Vox...  \n2109  ADNI_029_S_1073_PT_Coreg,_Avg,_Std_Img_and_Vox...  \n2110  ADNI_029_S_1073_PT_Coreg,_Avg,_Std_Img_and_Vox...  \n2111  ADNI_029_S_1073_PT_Coreg,_Avg,_Std_Img_and_Vox...  \n2112  ADNI_029_S_1073_MR_MPR-R__GradWarp__B1_Correct...  \n\n[2113 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Subject</th>\n      <th>Age</th>\n      <th>Modality</th>\n      <th>Group</th>\n      <th>Image Data ID</th>\n      <th>path</th>\n      <th>filename</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>128_S_0272</td>\n      <td>71</td>\n      <td>MRI</td>\n      <td>CN</td>\n      <td>68938</td>\n      <td>/kaggle/input/adnidata/ADNI/128_S_0272/MPR-R__...</td>\n      <td>ADNI_128_S_0272_MR_MPR-R__GradWarp__B1_Correct...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>128_S_0272</td>\n      <td>73</td>\n      <td>MRI</td>\n      <td>CN</td>\n      <td>105494</td>\n      <td>/kaggle/input/adnidata/ADNI/128_S_0272/MPR-R__...</td>\n      <td>ADNI_128_S_0272_MR_MPR-R__GradWarp__B1_Correct...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>128_S_0272</td>\n      <td>72</td>\n      <td>MRI</td>\n      <td>CN</td>\n      <td>69226</td>\n      <td>/kaggle/input/adnidata/ADNI/128_S_0272/MPR-R__...</td>\n      <td>ADNI_128_S_0272_MR_MPR-R__GradWarp__B1_Correct...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>128_S_0272</td>\n      <td>71</td>\n      <td>PET</td>\n      <td>CN</td>\n      <td>57334</td>\n      <td>/kaggle/input/adnidata/ADNI/128_S_0272/Coreg,_...</td>\n      <td>ADNI_128_S_0272_PT_Coreg,_Avg,_Standardized_Im...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>128_S_0272</td>\n      <td>74</td>\n      <td>PET</td>\n      <td>CN</td>\n      <td>149234</td>\n      <td>/kaggle/input/adnidata/ADNI/128_S_0272/Coreg,_...</td>\n      <td>ADNI_128_S_0272_PT_Coreg,_Avg,_Standardized_Im...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2108</th>\n      <td>029_S_1073</td>\n      <td>67</td>\n      <td>PET</td>\n      <td>MCI</td>\n      <td>1596802</td>\n      <td>/kaggle/input/adnidata/ADNI/029_S_1073/Coreg,_...</td>\n      <td>ADNI_029_S_1073_PT_Coreg,_Avg,_Std_Img_and_Vox...</td>\n    </tr>\n    <tr>\n      <th>2109</th>\n      <td>029_S_1073</td>\n      <td>67</td>\n      <td>PET</td>\n      <td>MCI</td>\n      <td>1596748</td>\n      <td>/kaggle/input/adnidata/ADNI/029_S_1073/Coreg,_...</td>\n      <td>ADNI_029_S_1073_PT_Coreg,_Avg,_Std_Img_and_Vox...</td>\n    </tr>\n    <tr>\n      <th>2110</th>\n      <td>029_S_1073</td>\n      <td>66</td>\n      <td>PET</td>\n      <td>MCI</td>\n      <td>1596851</td>\n      <td>/kaggle/input/adnidata/ADNI/029_S_1073/Coreg,_...</td>\n      <td>ADNI_029_S_1073_PT_Coreg,_Avg,_Std_Img_and_Vox...</td>\n    </tr>\n    <tr>\n      <th>2111</th>\n      <td>029_S_1073</td>\n      <td>68</td>\n      <td>PET</td>\n      <td>MCI</td>\n      <td>1596813</td>\n      <td>/kaggle/input/adnidata/ADNI/029_S_1073/Coreg,_...</td>\n      <td>ADNI_029_S_1073_PT_Coreg,_Avg,_Std_Img_and_Vox...</td>\n    </tr>\n    <tr>\n      <th>2112</th>\n      <td>029_S_1073</td>\n      <td>68</td>\n      <td>MRI</td>\n      <td>MCI</td>\n      <td>132818</td>\n      <td>/kaggle/input/adnidata/ADNI/029_S_1073/MPR-R__...</td>\n      <td>ADNI_029_S_1073_MR_MPR-R__GradWarp__B1_Correct...</td>\n    </tr>\n  </tbody>\n</table>\n<p>2113 rows × 7 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"mri_df = final_df[final_df['Modality'] == 'MRI']\nmri_paths = (mri_df['path'] +'/'+mri_df['filename']).to_numpy()\nmri_labels = mri_df['Group'].to_numpy()\n\npet_df = final_df[final_df['Modality'] == 'PET']\npet_paths = (pet_df['path'] +'/'+pet_df['filename']).to_numpy()\npet_labels = pet_df['Group'].to_numpy()","metadata":{"execution":{"iopub.status.busy":"2023-04-19T05:35:39.708451Z","iopub.execute_input":"2023-04-19T05:35:39.709138Z","iopub.status.idle":"2023-04-19T05:35:39.719667Z","shell.execute_reply.started":"2023-04-19T05:35:39.709093Z","shell.execute_reply":"2023-04-19T05:35:39.718781Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Dataloader to create the dataset and split into test and train images","metadata":{}},{"cell_type":"code","source":"'''\nclass CustomDataset(Dataset):\n    def __init__(self, image_paths, labels, transform=None):\n        self.image_paths = image_paths\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, index):\n        image_path = self.image_paths[index]\n        label = self.labels[index]\n        #image = nib.load(image_path).get_fdata()\n        #print(image.size())\n        image = sitk.ReadImage(image_path)\n        image = sitk.GetArrayFromImage(image)\n        if self.transform is not None:\n            image = self.transform(image)\n\n        return image, label\n\n# Define your image paths and labels as numpy arrays\nimage_paths = paths  # Replace with your own image paths\nlabels = labels  # Replace with your own labels\n'''\n#MRI\n# Perform 70-30 train-test split\nmri_train_image_paths, mri_test_image_paths, mri_train_labels, mri_test_labels = train_test_split(\n    mri_paths, mri_labels, test_size=0.3, random_state=42)\n\n\n#PET\npet_train_image_paths, pet_test_image_paths, pet_train_labels, pet_test_labels = train_test_split(\n    pet_paths, pet_labels, test_size=0.3, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-04-19T05:35:40.599072Z","iopub.execute_input":"2023-04-19T05:35:40.599401Z","iopub.status.idle":"2023-04-19T05:35:40.607259Z","shell.execute_reply.started":"2023-04-19T05:35:40.599377Z","shell.execute_reply":"2023-04-19T05:35:40.606333Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# print(mri_paths.shape)\n# print(mri_train_image_paths.shape)\n# print(mri_test_image_paths.shape)\n\n\n# print(pet_paths.shape)\n# print(pet_train_image_paths.shape)\n# print(pet_test_image_paths.shape)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-19T05:35:41.023205Z","iopub.execute_input":"2023-04-19T05:35:41.023475Z","iopub.status.idle":"2023-04-19T05:35:41.028030Z","shell.execute_reply.started":"2023-04-19T05:35:41.023452Z","shell.execute_reply":"2023-04-19T05:35:41.027095Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def pathstoarray(train_image_paths):\n    train_images = []\n    for image_path in train_image_paths:\n        # Read image using OpenCV\n        image = sitk.ReadImage(image_path)\n        image = sitk.GetArrayFromImage(image)\n        #print(image.shape)\n        # Convert BGR image to RGB\n        #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        # Append image to list\n        image = np.resize(image, (60, 128, 128))\n        train_images.append(image)\n    return train_images","metadata":{"execution":{"iopub.status.busy":"2023-04-19T05:35:42.029399Z","iopub.execute_input":"2023-04-19T05:35:42.029960Z","iopub.status.idle":"2023-04-19T05:35:42.035481Z","shell.execute_reply.started":"2023-04-19T05:35:42.029933Z","shell.execute_reply":"2023-04-19T05:35:42.034612Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# mri_train_images = np.array(pathstoarray(mri_train_image_paths))\n# mri_test_images = np.array(pathstoarray(mri_test_image_paths))","metadata":{"execution":{"iopub.status.busy":"2023-04-19T05:35:42.545924Z","iopub.execute_input":"2023-04-19T05:35:42.546924Z","iopub.status.idle":"2023-04-19T05:35:42.550380Z","shell.execute_reply.started":"2023-04-19T05:35:42.546893Z","shell.execute_reply":"2023-04-19T05:35:42.549529Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# pet_train_images = np.array(pathstoarray(pet_train_image_paths))\n# pet_test_images = np.array(pathstoarray(pet_test_image_paths))","metadata":{"execution":{"iopub.status.busy":"2023-04-19T05:35:42.876297Z","iopub.execute_input":"2023-04-19T05:35:42.877399Z","iopub.status.idle":"2023-04-19T05:35:42.881031Z","shell.execute_reply.started":"2023-04-19T05:35:42.877364Z","shell.execute_reply":"2023-04-19T05:35:42.880155Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# print(mri_train_images.shape)\n# print(mri_test_images.shape)\n\n# print(pet_train_images.shape)\n# print(pet_test_images.shape)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-19T05:35:43.169183Z","iopub.execute_input":"2023-04-19T05:35:43.169450Z","iopub.status.idle":"2023-04-19T05:35:43.173406Z","shell.execute_reply.started":"2023-04-19T05:35:43.169427Z","shell.execute_reply":"2023-04-19T05:35:43.172548Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# mri_train_pkl = 'mri_train_array.pkl'\n# with open(mri_train_pkl, 'wb') as f:\n#     pickle.dump(mri_train_images, f)\n\n# mri_test_pkl = 'mri_test_array.pkl'\n# with open(mri_test_pkl, 'wb') as f:\n#     pickle.dump(mri_test_images, f)\n    \n# pet_train_pkl = 'pet_train_array.pkl'\n# with open(pet_train_pkl, 'wb') as f:\n#     pickle.dump(pet_train_images, f)\n\n# pet_test_pkl = 'pet_test_array.pkl'\n# with open(pet_test_pkl, 'wb') as f:\n#     pickle.dump(pet_test_images, f)","metadata":{"execution":{"iopub.status.busy":"2023-04-19T05:35:43.580055Z","iopub.execute_input":"2023-04-19T05:35:43.580373Z","iopub.status.idle":"2023-04-19T05:35:43.584830Z","shell.execute_reply.started":"2023-04-19T05:35:43.580347Z","shell.execute_reply":"2023-04-19T05:35:43.583999Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/input/pickle-files/mri_train_array.pkl', 'rb') as f:\n    mri_train_images = pickle.load(f)\n\nwith open('/kaggle/input/pickle-files/mri_test_array.pkl', 'rb') as f:\n    mri_test_images = pickle.load(f)\n    \nwith open('/kaggle/input/pickle-files/pet_train_array.pkl', 'rb') as f:\n    pet_train_images = pickle.load(f)\n\nwith open('/kaggle/input/pickle-files/pet_test_array.pkl', 'rb') as f:\n    pet_test_images = pickle.load(f)\n\nprint(mri_train_images.shape)\nprint(mri_test_images.shape)\n\nprint(pet_train_images.shape)\nprint(pet_test_images.shape)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-19T05:35:44.195672Z","iopub.execute_input":"2023-04-19T05:35:44.196777Z","iopub.status.idle":"2023-04-19T05:36:32.358578Z","shell.execute_reply.started":"2023-04-19T05:35:44.196741Z","shell.execute_reply":"2023-04-19T05:36:32.357603Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"(510, 60, 128, 128)\n(219, 60, 128, 128)\n(968, 60, 128, 128)\n(416, 60, 128, 128)\n","output_type":"stream"}]},{"cell_type":"code","source":"classes = np.array(['MCI', 'CN', 'AD'])\n# Create a dictionary to map class names to their corresponding index values\nclass_to_idx = {class_name: idx for idx, class_name in enumerate(classes)}\n# Use a list comprehension to convert the class names to index values\nmri_labels_idx = np.array([class_to_idx[label] for label in mri_train_labels])\n# Use the index values to create the one-hot encoded labels\nmri_lb_oh = np.eye(len(classes))[mri_labels_idx]\nmri_train_data_model = mri_train_images[:, np.newaxis, :,:,:]\n\n\npet_labels_idx = np.array([class_to_idx[label] for label in pet_train_labels])\npet_lb_oh = np.eye(len(classes))[pet_labels_idx]\npet_train_data_model = pet_train_images[:, np.newaxis, :,:,:]","metadata":{"execution":{"iopub.status.busy":"2023-04-19T05:36:32.360441Z","iopub.execute_input":"2023-04-19T05:36:32.360784Z","iopub.status.idle":"2023-04-19T05:36:32.369362Z","shell.execute_reply.started":"2023-04-19T05:36:32.360753Z","shell.execute_reply":"2023-04-19T05:36:32.368571Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"print(mri_train_data_model.shape)\nprint(mri_lb_oh.shape)\n\nprint(pet_train_data_model.shape)\nprint(pet_lb_oh.shape)","metadata":{"execution":{"iopub.status.busy":"2023-04-19T05:36:32.370555Z","iopub.execute_input":"2023-04-19T05:36:32.370852Z","iopub.status.idle":"2023-04-19T05:36:32.396667Z","shell.execute_reply.started":"2023-04-19T05:36:32.370826Z","shell.execute_reply":"2023-04-19T05:36:32.395761Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"(510, 1, 60, 128, 128)\n(510, 3)\n(968, 1, 60, 128, 128)\n(968, 3)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## RESNET model implementation","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import Input, Conv3D, MaxPooling3D, ZeroPadding3D,\\\n     Flatten, BatchNormalization, AveragePooling3D, Dense, Activation, Add  , Concatenate\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import activations\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.regularizers import l2\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\nfrom tensorflow.keras import optimizers","metadata":{"execution":{"iopub.status.busy":"2023-04-19T05:36:32.398700Z","iopub.execute_input":"2023-04-19T05:36:32.398968Z","iopub.status.idle":"2023-04-19T05:37:12.170818Z","shell.execute_reply.started":"2023-04-19T05:36:32.398944Z","shell.execute_reply":"2023-04-19T05:37:12.169688Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"D0419 05:37:05.696332975      14 config.cc:119]                        gRPC EXPERIMENT tcp_frame_size_tuning               OFF (default:OFF)\nD0419 05:37:05.696368868      14 config.cc:119]                        gRPC EXPERIMENT tcp_rcv_lowat                       OFF (default:OFF)\nD0419 05:37:05.696372631      14 config.cc:119]                        gRPC EXPERIMENT peer_state_based_framing            OFF (default:OFF)\nD0419 05:37:05.696375567      14 config.cc:119]                        gRPC EXPERIMENT flow_control_fixes                  ON  (default:ON)\nD0419 05:37:05.696378155      14 config.cc:119]                        gRPC EXPERIMENT memory_pressure_controller          OFF (default:OFF)\nD0419 05:37:05.696381230      14 config.cc:119]                        gRPC EXPERIMENT unconstrained_max_quota_buffer_size OFF (default:OFF)\nD0419 05:37:05.696383890      14 config.cc:119]                        gRPC EXPERIMENT new_hpack_huffman_decoder           ON  (default:ON)\nD0419 05:37:05.696387577      14 config.cc:119]                        gRPC EXPERIMENT event_engine_client                 OFF (default:OFF)\nD0419 05:37:05.696390183      14 config.cc:119]                        gRPC EXPERIMENT monitoring_experiment               ON  (default:ON)\nD0419 05:37:05.696392772      14 config.cc:119]                        gRPC EXPERIMENT promise_based_client_call           OFF (default:OFF)\nD0419 05:37:05.696395508      14 config.cc:119]                        gRPC EXPERIMENT free_large_allocator                OFF (default:OFF)\nD0419 05:37:05.696398003      14 config.cc:119]                        gRPC EXPERIMENT promise_based_server_call           OFF (default:OFF)\nD0419 05:37:05.696400643      14 config.cc:119]                        gRPC EXPERIMENT transport_supplies_client_latency   OFF (default:OFF)\nD0419 05:37:05.696403185      14 config.cc:119]                        gRPC EXPERIMENT event_engine_listener               OFF (default:OFF)\nI0419 05:37:05.696624327      14 ev_epoll1_linux.cc:122]               grpc epoll fd: 67\nD0419 05:37:05.696641944      14 ev_posix.cc:144]                      Using polling engine: epoll1\nD0419 05:37:05.696665517      14 dns_resolver_ares.cc:822]             Using ares dns resolver\nD0419 05:37:05.697156223      14 lb_policy_registry.cc:46]             registering LB policy factory for \"priority_experimental\"\nD0419 05:37:05.697168302      14 lb_policy_registry.cc:46]             registering LB policy factory for \"outlier_detection_experimental\"\nD0419 05:37:05.697172117      14 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_target_experimental\"\nD0419 05:37:05.697175239      14 lb_policy_registry.cc:46]             registering LB policy factory for \"pick_first\"\nD0419 05:37:05.697178260      14 lb_policy_registry.cc:46]             registering LB policy factory for \"round_robin\"\nD0419 05:37:05.697181348      14 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_round_robin_experimental\"\nD0419 05:37:05.697205045      14 lb_policy_registry.cc:46]             registering LB policy factory for \"ring_hash_experimental\"\nD0419 05:37:05.697238432      14 lb_policy_registry.cc:46]             registering LB policy factory for \"grpclb\"\nD0419 05:37:05.697280095      14 lb_policy_registry.cc:46]             registering LB policy factory for \"rls_experimental\"\nD0419 05:37:05.697292649      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_manager_experimental\"\nD0419 05:37:05.697296299      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_impl_experimental\"\nD0419 05:37:05.697299517      14 lb_policy_registry.cc:46]             registering LB policy factory for \"cds_experimental\"\nD0419 05:37:05.697305403      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_resolver_experimental\"\nD0419 05:37:05.697308857      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_override_host_experimental\"\nD0419 05:37:05.697312185      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_wrr_locality_experimental\"\nD0419 05:37:05.697316489      14 certificate_provider_registry.cc:35]  registering certificate provider factory for \"file_watcher\"\nI0419 05:37:05.699968095      14 socket_utils_common_posix.cc:408]     Disabling AF_INET6 sockets because ::1 is not available.\nI0419 05:37:05.719505888     326 socket_utils_common_posix.cc:337]     TCP_USER_TIMEOUT is available. TCP_USER_TIMEOUT will be used thereafter\nE0419 05:37:05.727356070     326 oauth2_credentials.cc:236]            oauth_fetch: UNKNOWN:C-ares status is not ARES_SUCCESS qtype=A name=metadata.google.internal. is_balancer=0: Domain name not found {grpc_status:2, created_time:\"2023-04-19T05:37:05.727339732+00:00\"}\n","output_type":"stream"}]},{"cell_type":"code","source":"def res_identity(x, filters): \n  #renet block where dimension doesnot change.\n  #The skip connection is just simple identity conncection\n  #we will have 3 blocks and then input will be added\n\n  x_skip = x # this will be used for addition with the residual block \n  f1, f2 = filters\n\n  #first block \n  x = Conv3D(f1, kernel_size=(1,1, 1), strides=(1, 1,1), padding='valid', kernel_regularizer=l2(0.001))(x)\n  x = BatchNormalization()(x)\n  x = Activation(activations.relu)(x)\n\n  #second block # bottleneck (but size kept same with padding)\n  x = Conv3D(f1, kernel_size=(3,3, 3), strides=(1,1, 1), padding='same', kernel_regularizer=l2(0.001))(x)\n  x = BatchNormalization()(x)\n  x = Activation(activations.relu)(x)\n\n  # third block activation used after adding the input\n  x = Conv3D(f2, kernel_size=(1,1, 1), strides=(1,1, 1), padding='valid', kernel_regularizer=l2(0.001))(x)\n  x = BatchNormalization()(x)\n  # x = Activation(activations.relu)(x)\n\n  # add the input \n  x = Add()([x, x_skip])\n  x = Activation(activations.relu)(x)\n\n  return x\n\ndef res_conv(x, s, filters):\n  '''\n  here the input size changes''' \n  x_skip = x\n  f1, f2 = filters\n\n  # first block\n  x = Conv3D(f1, kernel_size=(1,1, 1), strides=(s,s, s), padding='valid', kernel_regularizer=l2(0.001))(x)\n  # when s = 2 then it is like downsizing the feature map\n  x = BatchNormalization()(x)\n  x = Activation(activations.relu)(x)\n\n  # second block\n  x = Conv3D(f1, kernel_size=(3,3, 3), strides=(1,1, 1), padding='same', kernel_regularizer=l2(0.001))(x)\n  x = BatchNormalization()(x)\n  x = Activation(activations.relu)(x)\n\n  #third block\n  x = Conv3D(f2, kernel_size=(1,1, 1), strides=(1,1, 1), padding='valid', kernel_regularizer=l2(0.001))(x)\n  x = BatchNormalization()(x)\n\n  # shortcut \n  x_skip = Conv3D(f2, kernel_size=(1, 1,1), strides=(s,s, s), padding='valid', kernel_regularizer=l2(0.001))(x_skip)\n  x_skip = BatchNormalization()(x_skip)\n\n  # add \n  x = Add()([x, x_skip])\n  x = Activation(activations.relu)(x)\n\n  return x","metadata":{"execution":{"iopub.status.busy":"2023-04-19T05:37:12.172214Z","iopub.execute_input":"2023-04-19T05:37:12.172787Z","iopub.status.idle":"2023-04-19T05:37:12.190000Z","shell.execute_reply.started":"2023-04-19T05:37:12.172757Z","shell.execute_reply":"2023-04-19T05:37:12.189264Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def resnet50():\n\n  input_im = Input(shape=(1,60, 128, 128,)) # cifar 10 images size,\n  x = ZeroPadding3D(padding=(1,1, 1))(input_im)\n\n  # 1st stage\n  # here we perform maxpooling, see the figure above\n\n  x = Conv3D(64, kernel_size=(3, 3,3), strides=(1,1, 1))(x)\n  x = BatchNormalization()(x)\n  x = Activation(activations.relu)(x)\n  x = MaxPooling3D((1,1, 1), strides=(1, 1,1))(x)\n\n  #2nd stage \n  # frm here on only conv block and identity block, no pooling\n\n  x = res_conv(x, s=1, filters=(16, 64))\n  x = res_identity(x, filters=(16, 64))\n  x = res_identity(x, filters=(16, 64))\n\n  # 3rd stage\n\n  x = res_conv(x, s=2, filters=(64, 256))\n  x = res_identity(x, filters=(64, 256))\n  x = res_identity(x, filters=(64, 256))\n  x = res_identity(x, filters=(64, 256))\n\n  # 4th stage\n\n  x = res_conv(x, s=2, filters=(64, 256))\n  x = res_identity(x, filters=(64, 256))\n  x = res_identity(x, filters=(64, 256))\n  x = res_identity(x, filters=(64, 256))\n  x = res_identity(x, filters=(64, 256))\n  x = res_identity(x, filters=(64, 256))\n\n  # 5th stage\n\n  x = res_conv(x, s=2, filters=(64, 256))\n  x = res_identity(x, filters=(64, 256))\n  x = res_identity(x, filters=(64, 256))\n\n  # ends with average pooling and dense connection\n\n  x = AveragePooling3D((2,2, 2), padding='same')(x)\n\n  x = Flatten()(x)\n  x = Dense(3, activation='softmax', kernel_initializer='he_normal')(x) #multi-class\n\n  # define the model \n\n  model = Model(inputs=input_im, outputs=x, name='Resnet50')\n\n  return model","metadata":{"execution":{"iopub.status.busy":"2023-04-19T05:37:12.191062Z","iopub.execute_input":"2023-04-19T05:37:12.191338Z","iopub.status.idle":"2023-04-19T05:37:12.209665Z","shell.execute_reply.started":"2023-04-19T05:37:12.191315Z","shell.execute_reply":"2023-04-19T05:37:12.208956Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"base_model_PET = resnet50()\n\nfc_layer1 = tf.keras.layers.Dense(512, activation='relu')(base_model_PET.layers[-2].output)\nfc_layer1 = tf.keras.layers.Dropout(0.8)(fc_layer1)\noutput_layer = tf.keras.layers.Dense(3, activation='sigmoid')(fc_layer1)\nPETmodel = Model(inputs=base_model_PET.input, outputs=output_layer)","metadata":{"execution":{"iopub.status.busy":"2023-04-19T05:37:12.210664Z","iopub.execute_input":"2023-04-19T05:37:12.210923Z","iopub.status.idle":"2023-04-19T05:37:17.893688Z","shell.execute_reply.started":"2023-04-19T05:37:12.210894Z","shell.execute_reply":"2023-04-19T05:37:17.892459Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"opt = optimizers.Adam(learning_rate=0.001)\nPETmodel.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\nPETmodel.fit(pet_train_data_model,pet_lb_oh,batch_size=16,epochs=20,verbose=1)","metadata":{"execution":{"iopub.status.busy":"2023-04-19T06:03:58.593825Z","iopub.execute_input":"2023-04-19T06:03:58.594341Z","iopub.status.idle":"2023-04-19T06:47:21.309278Z","shell.execute_reply.started":"2023-04-19T06:03:58.594311Z","shell.execute_reply":"2023-04-19T06:47:21.308049Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Epoch 1/20\n61/61 [==============================] - 151s 2s/step - loss: 3.1756 - accuracy: 0.5589\nEpoch 2/20\n61/61 [==============================] - 129s 2s/step - loss: 2.3281 - accuracy: 0.5682\nEpoch 3/20\n61/61 [==============================] - 129s 2s/step - loss: 1.9728 - accuracy: 0.5713\nEpoch 4/20\n61/61 [==============================] - 130s 2s/step - loss: 1.7256 - accuracy: 0.5733\nEpoch 5/20\n61/61 [==============================] - 129s 2s/step - loss: 1.6162 - accuracy: 0.5661\nEpoch 6/20\n61/61 [==============================] - 128s 2s/step - loss: 1.5848 - accuracy: 0.5775\nEpoch 7/20\n61/61 [==============================] - 129s 2s/step - loss: 1.5026 - accuracy: 0.5671\nEpoch 8/20\n61/61 [==============================] - 129s 2s/step - loss: 1.4814 - accuracy: 0.5661\nEpoch 9/20\n61/61 [==============================] - 129s 2s/step - loss: 1.5636 - accuracy: 0.5692\nEpoch 10/20\n61/61 [==============================] - 128s 2s/step - loss: 1.5026 - accuracy: 0.5723\nEpoch 11/20\n61/61 [==============================] - 129s 2s/step - loss: 1.4480 - accuracy: 0.5692\nEpoch 12/20\n61/61 [==============================] - 129s 2s/step - loss: 1.4175 - accuracy: 0.5702\nEpoch 13/20\n61/61 [==============================] - 129s 2s/step - loss: 1.3593 - accuracy: 0.5702\nEpoch 14/20\n61/61 [==============================] - 129s 2s/step - loss: 1.3255 - accuracy: 0.5713\nEpoch 15/20\n61/61 [==============================] - 128s 2s/step - loss: 1.2923 - accuracy: 0.5733\nEpoch 16/20\n61/61 [==============================] - 130s 2s/step - loss: 1.2669 - accuracy: 0.5713\nEpoch 17/20\n61/61 [==============================] - 129s 2s/step - loss: 1.2559 - accuracy: 0.5723\nEpoch 18/20\n61/61 [==============================] - 129s 2s/step - loss: 1.2327 - accuracy: 0.5723\nEpoch 19/20\n61/61 [==============================] - 129s 2s/step - loss: 1.2415 - accuracy: 0.5723\nEpoch 20/20\n61/61 [==============================] - 129s 2s/step - loss: 1.2986 - accuracy: 0.5723\n","output_type":"stream"},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f8c0828f2e0>"},"metadata":{}}]},{"cell_type":"code","source":"pet_test_labels_idx = np.array([class_to_idx[label] for label in pet_test_labels])\npet_test_data_model = pet_test_images[:, np.newaxis, :,:,:]\nprint(pet_test_data_model.shape)","metadata":{"execution":{"iopub.status.busy":"2023-04-19T06:47:24.452420Z","iopub.execute_input":"2023-04-19T06:47:24.453139Z","iopub.status.idle":"2023-04-19T06:47:24.458894Z","shell.execute_reply.started":"2023-04-19T06:47:24.453098Z","shell.execute_reply":"2023-04-19T06:47:24.457837Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"(416, 1, 60, 128, 128)\n","output_type":"stream"}]},{"cell_type":"code","source":"\ny_pred_probs = PETmodel.predict(pet_test_data_model)  # Predicted probabilities for each class\ny_pred = np.argmax(y_pred_probs, axis=1)  # Convert probabilities to class labels\n\n# Compute the confusion matrix\nconfusion_mat = confusion_matrix(pet_test_labels_idx, y_pred)\n\n# Compute evaluation metrics\naccuracy = accuracy_score(pet_test_labels_idx, y_pred)\nprecision = precision_score(pet_test_labels_idx, y_pred, average='weighted')\nrecall = recall_score(pet_test_labels_idx, y_pred, average='weighted')\nf1score = f1_score(pet_test_labels_idx, y_pred, average='weighted')\n\nprint(\"Confusion Matrix:\\n\", confusion_mat)\nprint(\"Accuracy: {:.4f}\".format(accuracy))\nprint(\"Precision: {:.4f}\".format(precision))\nprint(\"Recall: {:.4f}\".format(recall))\nprint(\"F1-score: {:.4f}\".format(f1score))","metadata":{"execution":{"iopub.status.busy":"2023-04-19T06:47:25.327047Z","iopub.execute_input":"2023-04-19T06:47:25.327418Z","iopub.status.idle":"2023-04-19T06:47:33.303806Z","shell.execute_reply.started":"2023-04-19T06:47:25.327390Z","shell.execute_reply":"2023-04-19T06:47:33.302626Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"13/13 [==============================] - 7s 408ms/step\nConfusion Matrix:\n [[240  11   0]\n [105  10   0]\n [ 50   0   0]]\nAccuracy: 0.6010\nPrecision: 0.4982\nRecall: 0.6010\nF1-score: 0.4890\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"print(y_pred_probs)","metadata":{"execution":{"iopub.status.busy":"2023-04-19T06:47:33.305562Z","iopub.execute_input":"2023-04-19T06:47:33.305852Z","iopub.status.idle":"2023-04-19T06:47:33.311084Z","shell.execute_reply.started":"2023-04-19T06:47:33.305826Z","shell.execute_reply":"2023-04-19T06:47:33.310048Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"[[0.63844955 0.50145686 0.29417235]\n [0.1141073  0.9787804  0.5527221 ]\n [0.638449   0.50145626 0.29417205]\n ...\n [0.638501   0.501458   0.2940642 ]\n [0.6384491  0.5014564  0.29417208]\n [0.63844913 0.5014565  0.29417214]]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model_MRI =resnet50()\n\nfc_layer = tf.keras.layers.Dense(512, activation='relu')(base_model_MRI.layers[-2].output)\nfc_layer = tf.keras.layers.Dropout(0.8)(fc_layer)\nfc_layer = Model(inputs=base_model_MRI.input, outputs=fc_layer)\n\n\nbase_model_PET = resnet50()\n\nfc_layer1 = tf.keras.layers.Dense(512, activation='relu')(base_model_PET.layers[-2].output)\nfc_layer1 = tf.keras.layers.Dropout(0.8)(fc_layer1)\nfc_layer1 = Model(inputs=base_model_PET.input, outputs=fc_layer1)\n\ncombined = Concatenate()([fc_layer.output, fc_layer1.output])\nz = Dense(2, activation=\"relu\")(combined)\noutput_layer = tf.keras.layers.Dense(3, activation='sigmoid')(z)\nmodel = tf.keras.models.Model(inputs=[base_model_MRI.input,base_model_PET.input], outputs=output_layer)","metadata":{"execution":{"iopub.status.busy":"2023-04-19T01:39:31.625238Z","iopub.execute_input":"2023-04-19T01:39:31.625561Z","iopub.status.idle":"2023-04-19T01:39:34.440162Z","shell.execute_reply.started":"2023-04-19T01:39:31.625532Z","shell.execute_reply":"2023-04-19T01:39:34.438820Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-17T16:49:18.892620Z","iopub.execute_input":"2023-04-17T16:49:18.893047Z","iopub.status.idle":"2023-04-17T16:49:18.898664Z","shell.execute_reply.started":"2023-04-17T16:49:18.893008Z","shell.execute_reply":"2023-04-17T16:49:18.897383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = train_data_model\nlabels = one_hot_train_labels","metadata":{"execution":{"iopub.status.busy":"2023-04-17T16:51:47.252875Z","iopub.execute_input":"2023-04-17T16:51:47.254176Z","iopub.status.idle":"2023-04-17T16:51:47.259071Z","shell.execute_reply.started":"2023-04-17T16:51:47.254108Z","shell.execute_reply":"2023-04-17T16:51:47.257915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile('adam','mse')","metadata":{"execution":{"iopub.status.busy":"2023-04-17T16:51:49.618935Z","iopub.execute_input":"2023-04-17T16:51:49.622290Z","iopub.status.idle":"2023-04-17T16:51:49.666297Z","shell.execute_reply.started":"2023-04-17T16:51:49.622151Z","shell.execute_reply":"2023-04-17T16:51:49.664715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit([data,data],labels,batch_size=16,epochs=2,verbose=1)","metadata":{"execution":{"iopub.status.busy":"2023-04-17T16:51:51.424806Z","iopub.execute_input":"2023-04-17T16:51:51.425219Z","iopub.status.idle":"2023-04-17T17:15:18.600941Z","shell.execute_reply.started":"2023-04-17T16:51:51.425183Z","shell.execute_reply":"2023-04-17T17:15:18.599860Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_images = []\nfor image_path in test_image_paths:\n    # Read image using OpenCV\n    image = sitk.ReadImage(image_path)\n    image = sitk.GetArrayFromImage(image)\n    #print(image.shape)\n    # Convert BGR image to RGB\n    #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    # Append image to list\n    image = np.resize(image, (60, 128, 128))\n    test_images.append(image)","metadata":{"execution":{"iopub.status.busy":"2023-04-17T17:20:28.048393Z","iopub.execute_input":"2023-04-17T17:20:28.048826Z","iopub.status.idle":"2023-04-17T17:21:56.582876Z","shell.execute_reply.started":"2023-04-17T17:20:28.048792Z","shell.execute_reply":"2023-04-17T17:21:56.581221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_images = np.array(test_images)\nprint(test_images.shape)\n\n\n# Use a list comprehension to convert the class names to index values\ntest_labels_idx = np.array([class_to_idx[label] for label in test_labels])\n\n# Use the index values to create the one-hot encoded labels\none_hot_test_labels = np.eye(len(classes))[test_labels_idx]\ntest_data_model = test_images[:, np.newaxis, :,:,:]\nprint(test_data_model.shape)\nprint(test_labels_idx)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-17T17:22:57.623023Z","iopub.execute_input":"2023-04-17T17:22:57.624102Z","iopub.status.idle":"2023-04-17T17:22:58.149355Z","shell.execute_reply.started":"2023-04-17T17:22:57.624059Z","shell.execute_reply":"2023-04-17T17:22:58.147989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_probs = model.predict([test_data_model,test_data_model])  # Predicted probabilities for each class\ny_pred = np.argmax(y_pred_probs, axis=1)  # Convert probabilities to class labels\n\n# Compute the confusion matrix\nconfusion_mat = confusion_matrix(test_labels_idx, y_pred)\n\n# Compute evaluation metrics\naccuracy = accuracy_score(test_labels_idx, y_pred)\nprecision = precision_score(test_labels_idx, y_pred, average='weighted')\nrecall = recall_score(test_labels_idx, y_pred, average='weighted')\nf1score = f1_score(test_labels_idx, y_pred, average='weighted')\n\nprint(\"Confusion Matrix:\\n\", confusion_mat)\nprint(\"Accuracy: {:.4f}\".format(accuracy))\nprint(\"Precision: {:.4f}\".format(precision))\nprint(\"Recall: {:.4f}\".format(recall))\nprint(\"F1-score: {:.4f}\".format(f1score))","metadata":{"execution":{"iopub.status.busy":"2023-04-17T17:27:38.412463Z","iopub.execute_input":"2023-04-17T17:27:38.413181Z","iopub.status.idle":"2023-04-17T17:29:04.425595Z","shell.execute_reply.started":"2023-04-17T17:27:38.413143Z","shell.execute_reply":"2023-04-17T17:29:04.424293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test_labels_idx)","metadata":{"execution":{"iopub.status.busy":"2023-04-17T17:46:47.068564Z","iopub.execute_input":"2023-04-17T17:46:47.069082Z","iopub.status.idle":"2023-04-17T17:46:47.076828Z","shell.execute_reply.started":"2023-04-17T17:46:47.069044Z","shell.execute_reply":"2023-04-17T17:46:47.075715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print(test_data_model)","metadata":{"execution":{"iopub.status.busy":"2023-04-17T18:06:02.170765Z","iopub.execute_input":"2023-04-17T18:06:02.171818Z","iopub.status.idle":"2023-04-17T18:06:02.176760Z","shell.execute_reply.started":"2023-04-17T18:06:02.171758Z","shell.execute_reply":"2023-04-17T18:06:02.175452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}